{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKZYJbBkBcOk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://qwiklabs-gcp-00-08c0fbdbe48b_accelerator_demo/...\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "import os\n",
    "PROJECT_ID = 'qwiklabs-gcp-00-08c0fbdbe48b'  # change here\n",
    "BUCKET = PROJECT_ID + '_accelerator_demo'\n",
    "REGION = 'us-central1'\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "!gsutil mb gs://{BUCKET}\n",
    "!gcloud config set compute/region {REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cavM78bf_mU4"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir train\n",
    "echo \"\" > train/__init__.py\n",
    "mkdir config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88-9WeCQ_mU9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/model_definition.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/model_definition.py\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.BatchNormalization(input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization(input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization(input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256))\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "    model.add(tf.keras.layers.Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T1aibldo_mVA"
   },
   "source": [
    "# Train on single Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R62Mk5QV_mVC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/train_single_cpu_gpu.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/train_single_cpu_gpu.py\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from . import model_definition\n",
    "\n",
    "#Get data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# add empty color dimension\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "#Train model\n",
    "\n",
    "model = model_definition.create_model(input_shape=x_train.shape[1:])\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['sparse_categorical_accuracy'])\n",
    "start = time.time()\n",
    "model.fit(\n",
    "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
    "    epochs=17,\n",
    "    steps_per_epoch=60,\n",
    "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
    "    validation_freq=17\n",
    ")\n",
    "print(\"Training time with single GPUs: {}\".format(time.time() - start))\n",
    "\n",
    "model.save_weights('./fashion_mnist_single.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsriilQA_mVE"
   },
   "source": [
    "## Submit single worker with CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 1: set module name defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9sTpINs_mVF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: single_cpu_fashion_minst_20210528_061337\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [single_cpu_fashion_minst_20210528_061337] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe single_cpu_fashion_minst_20210528_061337\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs single_cpu_fashion_minst_20210528_061337\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"single_cpu_fashion_minst_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --package-path=train \\\n",
    "  --module-name=train.train_single_cpu_gpu \\\n",
    "  --runtime-version=2.1 \\\n",
    "  --python-version=3.7 \\\n",
    "  --region=us-central1 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sdX5kB2_mVI"
   },
   "source": [
    "## Submit single worker with single GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 2: set module name defined above\n",
    "\n",
    "TODO 3: set `scale-tier` to prefefined single GPU tier. Refer to [this page](https://cloud.google.com/ai-platform/training/docs/machine-types#scale_tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY2FQRxB_mVI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: single_gpu_fashion_minst_20210528_061440\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [single_gpu_fashion_minst_20210528_061440] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe single_gpu_fashion_minst_20210528_061440\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs single_gpu_fashion_minst_20210528_061440\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"single_gpu_fashion_minst_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --package-path=train \\\n",
    "  --module-name=train.train_single_cpu_gpu \\\n",
    "  --runtime-version=2.1 \\\n",
    "  --python-version=3.7 \\\n",
    "  --region=us-central1 \\\n",
    "  --scale-tier=BASIC_GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFhtQb7vmgGg"
   },
   "source": [
    "# Train on multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 4: Define distribute strategy for multiple GPU on single machine. Refer to [this page](https://www.tensorflow.org/guide/distributed_training)\n",
    "\n",
    "TODO 5: Define scope of distribution strategy.\n",
    "\n",
    "TODO 6: Specify 4 NVIDIA Tesla K80 GPU in config yaml file. Refere to [this page](https://cloud.google.com/ai-platform/training/docs/using-gpus)\n",
    "\n",
    "TODO 7: Specify the module and config file in training submit command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yh3kCoYjmeh3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/train_mult_cpu_gpu.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/train_mult_cpu_gpu.py\n",
    "import os\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from . import model_definition\n",
    "\n",
    "#Get data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# add empty color dimension\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "##################### Multiple GPUs or CPUs ###################\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "###############################################################\n",
    "    model = model_definition.create_model(input_shape=x_train.shape[1:])\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['sparse_categorical_accuracy'])\n",
    "start = time.time()\n",
    "model.fit(\n",
    "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
    "    epochs=17,\n",
    "    steps_per_epoch=60,\n",
    "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
    "    validation_freq=17\n",
    ")\n",
    "print(\"Training time with multiple GPUs: {}\".format(time.time() - start))\n",
    "model.save_weights('./fashion_mnist_mult_gpu.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqujUt-nmlbD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config/multi_gpu_config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/multi_gpu_config.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  # Configure a master worker with 4 T4 GPUs\n",
    "  masterType: n1-highcpu-16\n",
    "  masterConfig:\n",
    "    acceleratorConfig:\n",
    "      count: 4\n",
    "      type: NVIDIA_TESLA_K80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "648UP-Timnvx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: multi_gpu_fashion_minst_20210528_061655\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [multi_gpu_fashion_minst_20210528_061655] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe multi_gpu_fashion_minst_20210528_061655\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs multi_gpu_fashion_minst_20210528_061655\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"multi_gpu_fashion_minst_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --package-path=train \\\n",
    "  --module-name=train.train_mult_cpu_gpu \\\n",
    "  --runtime-version=2.1 \\\n",
    "  --python-version=3.7 \\\n",
    "  --region=us-central1 \\\n",
    "  --config config/multi_gpu_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDO-FeOe_mVX"
   },
   "source": [
    "# Example training on TPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 9: Write code for TPU training by Refering to [this page](https://www.tensorflow.org/guide/tpu). No need to pass any arguments in TPUClusterResolver class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "im0jb-J3_mVX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/train_tpu.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/train_tpu.py\n",
    "import os\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from . import model_definition\n",
    "\n",
    "#Get data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# add empty color dimension\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "##################### Run on TPUs ###################\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "###############################################################\n",
    "    model = model_definition.create_model(input_shape=x_train.shape[1:])\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['sparse_categorical_accuracy'])\n",
    "start = time.time()\n",
    "model.fit(\n",
    "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
    "    epochs=17,\n",
    "    steps_per_epoch=60,\n",
    "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
    "    validation_freq=17\n",
    ")\n",
    "print(\"Training time with TPUs: {}\".format(time.time() - start))\n",
    "model.save_weights('./fashion_mnist_tpu.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-gPqTmi_mVZ"
   },
   "source": [
    "## Submit single worker with TPUv2 Pod (8 cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 10: set module name defined above\n",
    "\n",
    "TODO 11: set `scale-tier` to prefefined single TPU tier. Refer to [this page](https://cloud.google.com/ai-platform/training/docs/machine-types#scale_tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DMQpJjx_mVZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: tpu_fashion_minst_20210528_061847\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [tpu_fashion_minst_20210528_061847] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe tpu_fashion_minst_20210528_061847\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs tpu_fashion_minst_20210528_061847\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"tpu_fashion_minst_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --package-path=train \\\n",
    "  --module-name=train.train_tpu \\\n",
    "  --runtime-version=2.1 \\\n",
    "  --python-version=3.7 \\\n",
    "  --scale-tier=BASIC_TPU \\\n",
    "  --region=us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yEfabdrs_mVb"
   },
   "source": [
    "## Submit single worker TPUv3 (8 cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 12: specify 8 TPU V3 for accelerator by refering to [this page](https://cloud.google.com/ai-platform/training/docs/reference/rest/v1/AcceleratorType)\n",
    "\n",
    "TODO 13: Specify the module and config file in training submit command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eA5JSc__mVc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config/tpuv3_config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/tpuv3_config.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  masterType: n1-highcpu-16\n",
    "  workerType: cloud_tpu\n",
    "  workerCount: 1\n",
    "  workerConfig:\n",
    "    acceleratorConfig:\n",
    "      type: TPU_V3\n",
    "      count: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TMUOD_m5_mVe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: tpu_v3_fashion_minst_20210528_062012\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [tpu_v3_fashion_minst_20210528_062012] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe tpu_v3_fashion_minst_20210528_062012\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs tpu_v3_fashion_minst_20210528_062012\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"tpu_v3_fashion_minst_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --package-path=train \\\n",
    "  --module-name=train.train_tpu \\\n",
    "  --runtime-version=2.1 \\\n",
    "  --python-version=3.7 \\\n",
    "  --region=us-central1 \\\n",
    "  --config config/tpuv3_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_U-u_tZ_mVK"
   },
   "source": [
    "# Train on multiple device with GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 14: Specify distribute strategy for multiple device GPU training\n",
    "\n",
    "TODO 15: Specify master node with 4 NVIDIA TESLA K80, 3 worker node with 4 NVIDIA TESLA K80.\n",
    "\n",
    "TODO 16: Specify the module and config file in training submit command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_AF4VDhT_mVg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/train_mult_worker_mirrored.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/train_mult_worker_mirrored.py\n",
    "import os\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from . import model_definition\n",
    "\n",
    "#Get data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# add empty color dimension\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "##################### Run on multiple workers with GPU ###################\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "###############################################################\n",
    "\n",
    "    model = model_definition.create_model(input_shape=x_train.shape[1:])\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['sparse_categorical_accuracy'])\n",
    "start = time.time()\n",
    "model.fit(\n",
    "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
    "    epochs=17,\n",
    "    steps_per_epoch=60,\n",
    "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
    "    validation_freq=17\n",
    ")\n",
    "print(\"Training time with multiple GPUs: {}\".format(time.time() - start))\n",
    "model.save_weights('./fashion_mnist_mult_mirrored.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCGWARBH_mVi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config/multi_worker_gpu.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/multi_worker_gpu.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  # Configure a master worker with 4 T4 GPUs\n",
    "  masterType: n1-highcpu-16\n",
    "  masterConfig:\n",
    "    acceleratorConfig:\n",
    "      count: 4\n",
    "      type: NVIDIA_TESLA_K80\n",
    "  # Configure 3 workers, each with 4 T4 GPUs\n",
    "  workerCount: 3\n",
    "  workerType: n1-highcpu-16\n",
    "  workerConfig:\n",
    "    acceleratorConfig:\n",
    "      count: 4\n",
    "      type: NVIDIA_TESLA_K80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmXeeg6r_mVk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: multi_worker_gpu_fashion_minst_20210528_062146\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [multi_worker_gpu_fashion_minst_20210528_062146] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe multi_worker_gpu_fashion_minst_20210528_062146\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs multi_worker_gpu_fashion_minst_20210528_062146\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"multi_worker_gpu_fashion_minst_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --package-path=train \\\n",
    "  --module-name=train.train_mult_worker_mirrored \\\n",
    "  --runtime-version=2.1 \\\n",
    "  --python-version=3.7 \\\n",
    "  --region=us-central1 \\\n",
    "  --config config/multi_worker_gpu.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1biuGSM_mVm"
   },
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "accelarators_demo.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
